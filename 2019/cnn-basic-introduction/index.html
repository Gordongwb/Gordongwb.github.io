<!DOCTYPE html>
<html lang="en-us">
  <head>
  <meta http-equiv="content-type" content="text/html;charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="robots" content="noodp"/>
  <meta name="author" content="Gordon.Kwok">
  
  
  
  <link rel="prev" href="https://gordongwb.github.io/2019/v2ray-simple-configuration/" />
  <link rel="next" href="https://gordongwb.github.io/2019/lstm-basic-introduction/" />
  <link rel="canonical" href="https://gordongwb.github.io/2019/cnn-basic-introduction/" />
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">
  <title>
       
       
           CNN Basic Introduction | Gordon&#39;s Blog
       
  </title>
  <meta name="title" content="CNN Basic Introduction | Gordon&#39;s Blog">
    
  
  <link rel="stylesheet" href="/font/iconfont.css">
  <link rel="stylesheet" href="/css/main.min.css">


  
  
 

<script type="application/ld+json">
 "@context" : "http://schema.org",
    "@type" : "BlogPosting",
    "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "https:\/\/gordongwb.github.io"
    },
    "articleSection" : "posts",
    "name" : "CNN Basic Introduction",
    "headline" : "CNN Basic Introduction",
    "description" : "对于图像应用，我们经常在神经网络上使用卷积（Convolutional Neural Network），通常缩写为CNN。 下图为CNN的基本模型: 卷积神经网络的层级结构\n 数据输入层\/ Input layer 卷积计算层\/ CONV layer ReLU激励层 \/ ReLU layer 池化层 \/ Pooling layer 全连接层 \/ FC layer  一般为一般CNN结构依次为\n INPUT [[CONV -\x26gt; RELU]*N -\x26gt; POOL?]*M [FC -\x26gt; RELU]*K FC  基础原理 一般的，CNN的基本结构包括两层，其一为特征提取层，每个神经元的输入与前一层的局部接受域相连，并提取该局部的特征。一旦该局部特征被提取后，它与其它特征间的位置关系也随之确定下来；其二是特征映射层，网络的每个计算层由多个特征映射组成，每个特征映射是一个平面，平面上所有神经元的权值相等。特征映射结构采用影响函数核小的sigmoid函数作为卷积网络的激活函数，使得特征映射具有位移不变性。此外，由于一个映射面上的神经元共享权值，因而减少了网络自由参数的个数。卷积神经网络中的每一个卷积层都紧跟着一个用来求局部平均与二次提取的计算层，这种特有的两次特征提取结构减小了特征分辨率。\n　CNN主要用来识别位移、缩放及其他形式扭曲不变性的二维图形，该部分功能主要由池化层实现。由于CNN的特征检测层通过训练数据进行学习，所以在使用CNN时，避免了显式的特征抽取，而隐式地从训练数据中进行学习；再者由于同一特征映射面上的神经元权值相同，所以网络可以并行学习，这也是卷积网络相对于神经元彼此相连网络的一大优势。卷积神经网络以其局部权值共享的特殊结构在语音识别和图像处理方面有着独特的优越性，其布局更接近于实际的生物神经网络，权值共享降低了网络的复杂性，特别是多维输入向量的图像可以直接输入网络这一特点避免了特征提取和分类过程中数据重建的复杂度。\n简单示例 假设给定一张图（可能是字母X或者字母O），通过CNN即可识别出是X还是O，如下图所示，那怎么做到的呢\n如果采用经典的神经网络模型，则需要读取整幅图像作为神经网络模型的输入（即全连接的方式），当图像的尺寸越大时，其连接的参数将变得很多，从而导致计算量非常大。 而我们人类对外界的认知一般是从局部到全局，先对局部有感知的认识，再逐步对全体有认知，这是人类的认识模式。在图像中的空间联系也是类似，局部范围内的像素之间联系较为紧密，而距离较远的像素则相关性较弱。因而，每个神经元其实没有必要对全局图像进行感知，只需要对局部进行感知，然后在更高层将局部的信息综合起来就得到了全局的信息。这种模式就是卷积神经网络中降低参数数目的重要神器：局部感受野。\n如果字母X、字母O是固定不变的，那么最简单的方式就是图像之间的像素一一比对就行，但在现实生活中，字体都有着各个形态上的变化（例如手写文字识别），例如平移、缩放、旋转、微变形等等，如下图所示：\n我们的目标是对于各种形态变化的X和O，都能通过CNN准确地识别出来，这就涉及到应该如何有效地提取特征，作为识别的关键因子。回想前面讲到的“局部感受野”模式，对于CNN来说，它是一小块一小块地来进行比对，在两幅图像中大致相同的位置找到一些粗糙的特征（小块图像）进行匹配，相比起传统的整幅图逐一比对的方式，CNN的这种小块匹配方式能够更好的比较两幅图像之间的相似性。如下图：\n以字母X为例，可以提取出三个重要特征（两个交叉线、一个对角线），如下图所示\n假如以像素值\x26quot;1\x26quot;代表白色，像素值\x26rdquo;-1\x26quot;代表黑色，则字母X的三个重要特征如下：\n那么我们通过匹配图片的特征就可以识别出图片\n卷积层介绍 这一层就是卷积神经网络最重要的一个层次，也是“卷积神经网络”的名字来源。 在这个卷积层，有两个关键操作：\n 局部关联。每个神经元看做一个滤波器(filter) 窗口(receptive field)滑动， filter对局部数据计算  卷积层重要名词：\n 深度\/depth（解释见下图） 步长\/stride （窗口一次滑动的长度） 填充值\/zero-padding  填充值是什么呢？以下图为例子，比如有这么一个55的图片（一个格子一个像素），我们滑动窗口取22，步长取2，那么我们发现还剩下1个像素没法滑完，那怎么办呢？\n那我们在原先的矩阵加了一层填充值，使得变成6*6的矩阵，那么窗口就可以刚好把所有像素遍历完。这就是填充值的作用。 卷积的计算（注意，下面蓝色矩阵周围有一圈灰色的框，那些就是上面所说到的填充值） 蓝色的矩阵(输入图像)对粉色的矩阵（filter）进行矩阵内积计算并将三个内积运算的结果与偏置值b相加,如图： 应用 卷积神经网络之典型CNN",
    "inLanguage" : "en-us",
    "author" : "Gordon.Kwok",
    "creator" : "Gordon.Kwok",
    "publisher": "Gordon.Kwok",
    "accountablePerson" : "Gordon.Kwok",
    "copyrightHolder" : "Gordon.Kwok",
    "copyrightYear" : "2019",
    "datePublished": "2019-12-25 21:20:35 \x2b0800 CST",
    "dateModified" : "2019-12-25 21:20:35 \x2b0800 CST",
    "url" : "https:\/\/gordongwb.github.io\/2019\/cnn-basic-introduction\/",
    "wordCount" : "84",
    "keywords" : [ "“ML”","“CNN”", "Gordon\x27s Blog"]
}
</script>

</head>

  


  <body class="">
    <div class="wrapper">
        <nav class="navbar">
    <div class="container">
        <div class="navbar-header header-logo">
        	<a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-xihuan"></i></a>&nbsp;<a href="https://gordongwb.github.io">Gordon&#39;s Blog</a>
        </div>
        <div class="menu navbar-right">
                
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
                <a class="menu-item" href="/categories/" title="">Categories</a>
                
                <a class="menu-item" href="/tags/" title="">Tags</a>
                
                <a class="menu-item" href="/about/" title="About My Blog">About My Blog</a>
                
        </div>
    </div>
</nav>
<nav class="navbar-mobile" id="nav-mobile" style="display: none">
     <div class="container">
        <div class="navbar-header">
            <div>  <a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-xihuan"></i></a>&nbsp;<a href="https://gordongwb.github.io">Gordon&#39;s Blog</a></div>
            <div class="menu-toggle">
                <span></span><span></span><span></span>
            </div>
        </div>
     
          <div class="menu" id="mobile-menu">
                
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
                <a class="menu-item" href="/categories/" title="">Categories</a>
                
                <a class="menu-item" href="/tags/" title="">Tags</a>
                
                <a class="menu-item" href="/about/" title="About My Blog">About My Blog</a>
                
        </div>
    </div>
</nav>
    	 <main class="main">
          <div class="container">
      		
<article class="post-warp" itemscope itemtype="http://schema.org/Article">
    <header class="post-header">
        <h1 class="post-title" itemprop="name headline">CNN Basic Introduction</h1>
        <div class="post-meta">
                Written by <a itemprop="name" href="https://gordongwb.github.io" rel="author">Gordon.Kwok</a> with ♥ 
                <span class="post-time">
                on <time datetime=2019-12-25 itemprop="datePublished">December 25, 2019</time>
                </span>
                in
                <i class="iconfont icon-folder"></i>
                <span class="post-category">
                        <a href="https://gordongwb.github.io/categories/machine-learning/"> “Machine Learning” </a>
                        
                </span>
        </div>
    </header>
    <div class="post-content">
        

        
            
        

        
        
     
          
          
          

          
          
          

          <p>对于图像应用，我们经常在神经网络上使用卷积（Convolutional Neural Network），通常缩写为CNN。
下图为CNN的基本模型:
<img src="https://pic3.zhimg.com/v2-7a147703c5181ff9737b41afa6ea6bce_1200x500.jpg" alt="">
<img src="https://images2015.cnblogs.com/blog/1093303/201704/1093303-20170430194254881-664443051.jpg" alt=""></p>
<p>卷积神经网络的层级结构</p>
<ul>
<li>数据输入层/ Input layer</li>
<li>卷积计算层/ CONV layer</li>
<li>ReLU激励层 / ReLU layer</li>
<li>池化层 / Pooling layer</li>
<li>全连接层 / FC layer</li>
</ul>
<p>一般为一般CNN结构依次为</p>
<ol>
<li>INPUT</li>
<li>[[CONV -&gt; RELU]*N -&gt; POOL?]*M</li>
<li>[FC -&gt; RELU]*K</li>
<li>FC</li>
</ol>
<h2 id="基础原理">基础原理</h2>
<p>一般的，CNN的基本结构包括两层，其一为特征提取层，每个神经元的输入与前一层的局部接受域相连，并提取该局部的特征。一旦该局部特征被提取后，它与其它特征间的位置关系也随之确定下来；其二是特征映射层，网络的每个计算层由多个特征映射组成，每个特征映射是一个平面，平面上所有神经元的权值相等。特征映射结构采用影响函数核小的sigmoid函数作为卷积网络的激活函数，使得特征映射具有位移不变性。此外，由于一个映射面上的神经元共享权值，因而减少了网络自由参数的个数。卷积神经网络中的每一个卷积层都紧跟着一个用来求局部平均与二次提取的计算层，这种特有的两次特征提取结构减小了特征分辨率。</p>
<p>　　CNN主要用来识别位移、缩放及其他形式扭曲不变性的二维图形，该部分功能主要由池化层实现。由于CNN的特征检测层通过训练数据进行学习，所以在使用CNN时，避免了显式的特征抽取，而隐式地从训练数据中进行学习；再者由于同一特征映射面上的神经元权值相同，所以网络可以并行学习，这也是卷积网络相对于神经元彼此相连网络的一大优势。卷积神经网络以其局部权值共享的特殊结构在语音识别和图像处理方面有着独特的优越性，其布局更接近于实际的生物神经网络，权值共享降低了网络的复杂性，特别是多维输入向量的图像可以直接输入网络这一特点避免了特征提取和分类过程中数据重建的复杂度。</p>
<h3 id="简单示例">简单示例</h3>
<p>假设给定一张图（可能是字母X或者字母O），通过CNN即可识别出是X还是O，如下图所示，那怎么做到的呢</p>
<p><img src="https://img2018.cnblogs.com/blog/1226410/201810/1226410-20181009202515631-1056461501.png" alt=""></p>
<p>如果采用经典的神经网络模型，则需要读取整幅图像作为神经网络模型的输入（即全连接的方式），当图像的尺寸越大时，其连接的参数将变得很多，从而导致计算量非常大。
　　而我们人类对外界的认知一般是从局部到全局，先对局部有感知的认识，再逐步对全体有认知，这是人类的认识模式。在图像中的空间联系也是类似，局部范围内的像素之间联系较为紧密，而距离较远的像素则相关性较弱。因而，每个神经元其实没有必要对全局图像进行感知，只需要对局部进行感知，然后在更高层将局部的信息综合起来就得到了全局的信息。这种模式就是卷积神经网络中降低参数数目的重要神器：局部感受野。</p>
<p><img src="https://img2018.cnblogs.com/blog/1226410/201810/1226410-20181009202559906-1527391226.png" alt=""></p>
<p>如果字母X、字母O是固定不变的，那么最简单的方式就是图像之间的像素一一比对就行，但在现实生活中，字体都有着各个形态上的变化（例如手写文字识别），例如平移、缩放、旋转、微变形等等，如下图所示：</p>
<p><img src="https://img2018.cnblogs.com/blog/1226410/201810/1226410-20181009202627271-1361985686.png" alt=""></p>
<p>我们的目标是对于各种形态变化的X和O，都能通过CNN准确地识别出来，这就涉及到应该如何有效地提取特征，作为识别的关键因子。回想前面讲到的“局部感受野”模式，对于CNN来说，它是一小块一小块地来进行比对，在两幅图像中大致相同的位置找到一些粗糙的特征（小块图像）进行匹配，相比起传统的整幅图逐一比对的方式，CNN的这种小块匹配方式能够更好的比较两幅图像之间的相似性。如下图：</p>
<p><img src="https://img2018.cnblogs.com/blog/1226410/201810/1226410-20181009202646989-200335159.png" alt=""></p>
<p>以字母X为例，可以提取出三个重要特征（两个交叉线、一个对角线），如下图所示</p>
<p><img src="https://img2018.cnblogs.com/blog/1226410/201810/1226410-20181009202702561-93616180.png" alt=""></p>
<p>假如以像素值&quot;1&quot;代表白色，像素值&rdquo;-1&quot;代表黑色，则字母X的三个重要特征如下：</p>
<p><img src="https://img2018.cnblogs.com/blog/1226410/201810/1226410-20181009202719374-1192154873.png" alt=""></p>
<p>那么我们通过匹配图片的特征就可以识别出图片</p>
<h3 id="卷积层介绍">卷积层介绍</h3>
<p>这一层就是卷积神经网络最重要的一个层次，也是“卷积神经网络”的名字来源。
在这个卷积层，有两个关键操作：</p>
<ul>
<li>局部关联。每个神经元看做一个滤波器(filter)</li>
<li>窗口(receptive field)滑动， filter对局部数据计算</li>
</ul>
<p>卷积层重要名词：</p>
<ul>
<li>深度/depth（解释见下图）</li>
<li>步长/stride （窗口一次滑动的长度）</li>
<li>填充值/zero-padding</li>
</ul>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201704/1093303-20170430194425147-845167791.png" alt=""></p>
<p>填充值是什么呢？以下图为例子，比如有这么一个5<em>5的图片（一个格子一个像素），我们滑动窗口取2</em>2，步长取2，那么我们发现还剩下1个像素没法滑完，那怎么办呢？</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201704/1093303-20170430194452615-1175169258.png" alt=""></p>
<p>那我们在原先的矩阵加了一层填充值，使得变成6*6的矩阵，那么窗口就可以刚好把所有像素遍历完。这就是填充值的作用。
<img src="https://images2015.cnblogs.com/blog/1093303/201704/1093303-20170430194526537-1629104898.png" alt=""></p>
<p>卷积的计算（注意，下面蓝色矩阵周围有一圈灰色的框，那些就是上面所说到的填充值）
<img src="https://images2015.cnblogs.com/blog/1093303/201704/1093303-20170430194547100-2091436500.jpg" alt=""></p>
<p>蓝色的矩阵(输入图像)对粉色的矩阵（filter）进行矩阵内积计算并将三个内积运算的结果与偏置值b相加,如图：
<img src="https://images2015.cnblogs.com/blog/1093303/201704/1093303-20170430194806256-1671846037.png" alt=""></p>
<h3 id="应用">应用</h3>
<p>卷积神经网络之典型CNN</p>
<ul>
<li>LeNet，这是最早用于数字识别的CNN</li>
<li>AlexNet， 2012 ILSVRC比赛远超第2名的CNN，比</li>
<li>LeNet更深，用多层小卷积层叠加替换单大卷积层。</li>
<li>ZF Net， 2013 ILSVRC比赛冠军</li>
<li>GoogLeNet， 2014 ILSVRC比赛冠军</li>
<li>VGGNet， 2014 ILSVRC比赛中的模型，图像识别略差于GoogLeNet，但是在很多图像转化学习问题(比如object detection)上效果奇好</li>
</ul>
<h2 id="总结">总结</h2>
<p>卷积网络在本质上是一种输入到输出的映射，它能够学习大量的输入与输出之间的映射关系，而不需要任何输入和输出之间的精确的数学表达式，只要用已知的模式对卷积网络加以训练，网络就具有输入输出对之间的映射能力。</p>
<p>CNN一个非常重要的特点就是头重脚轻（越往输入权值越小，越往输出权值越多），呈现出一个倒三角的形态，这就很好地避免了BP神经网络中反向传播的时候梯度损失得太快。</p>
<p>卷积神经网络CNN主要用来识别位移、缩放及其他形式扭曲不变性的二维图形。由于CNN的特征检测层通过训练数据进行学习，所以在使用CNN时，避免了显式的特征抽取，而隐式地从训练数据中进行学习；再者由于同一特征映射面上的神经元权值相同，所以网络可以并行学习，这也是卷积网络相对于神经元彼此相连网络的一大优势。卷积神经网络以其局部权值共享的特殊结构在语音识别和图像处理方面有着独特的优越性，其布局更接近于实际的生物神经网络，权值共享降低了网络的复杂性，特别是多维输入向量的图像可以直接输入网络这一特点避免了特征提取和分类过程中数据重建的复杂度。</p>

    </div>

    <div class="post-copyright">
             
            <p class="copyright-item">
                <span>Author:</span>
                <span>Gordon.Kwok </span>
                </p>
            
           
             
            <p class="copyright-item">
                    <span>Link:</span>
                    <a href=https://gordongwb.github.io/2019/cnn-basic-introduction/>https://gordongwb.github.io/2019/cnn-basic-introduction/</span>
            </p>
            
             
            <p class="copyright-item lincese">
                本文采用<a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可
            </p>
            
    </div>

  
    <div class="post-tags">
        
            <section>
            <i class="iconfont icon-tag"></i>Tag(s): 
            
            <span class="tag"><a href="https://gordongwb.github.io/tags/ml/">
                    #“ML”</a></span>
            
            <span class="tag"><a href="https://gordongwb.github.io/tags/cnn/">
                    #“CNN”</a></span>
            
            </section>
        
        <section>
                <a href="javascript:window.history.back();">back</a></span> · 
                <span><a href="https://gordongwb.github.io">home</a></span>
        </section>
    </div>

    <div class="post-nav">
        
        <a href="https://gordongwb.github.io/2019/v2ray-simple-configuration/" class="prev" rel="prev" title="V2ray Simple Configuration"><i class="iconfont icon-left"></i>&nbsp;V2ray Simple Configuration</a>
         
        
        <a href="https://gordongwb.github.io/2019/lstm-basic-introduction/" class="next" rel="next" title="LSTM Basic_Introduction">LSTM Basic_Introduction&nbsp;<i class="iconfont icon-right"></i></a>
        
    </div>

    <div class="post-comment">
          
                 
          
    </div>
</article>
          </div>
		   </main>
      <footer class="footer">
    <div class="copyright">
        &copy;
        
        <span itemprop="copyrightYear">2016 - 2020</span>
        
        <span class="with-love">
    	 <i class="iconfont icon-love"></i> 
         </span>
         
            <span class="author" itemprop="copyrightHolder"><a href="https://gordongwb.github.io">Gordon.Kwok</a> | </span> 
         

         
		  <span>Powered by <a href="https://gohugo.io/" target="_blank" rel="external nofollow">Hugo</a> & <a href="https://github.com/liuzc/leaveit" target="_blank" rel="external nofollow">LeaveIt</a></span> 
    </div>
</footer>












    
     <link href="//lib.baomitu.com/lightgallery/1.6.11/css/lightgallery.min.css" rel="stylesheet">  
      
     <script src="/js/vendor_gallery.min.js" async="" ></script>
    
  



     </div>
  </body>
</html>
